import cv2
import mediapipe as mp
import time
import numpy as np

cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FPS, 60)

mpHands = mp.solutions.hands
hands = mpHands.Hands(
    max_num_hands=2,
    min_detection_confidence=0.6,
    min_tracking_confidence=0.6
)
mpDraw = mp.solutions.drawing_utils

mpFace = mp.solutions.face_detection
faceDetection = mpFace.FaceDetection(
    model_selection=0,
    min_detection_confidence=0.55
)

prev_bbox = None
alpha = 0.25
frame_count = 0

while True:
    success, img = cap.read()
    if not success:
        print("Camera error")
        continue

    img = cv2.flip(img, 1)
    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    handResults = hands.process(imgRGB)
    if handResults.multi_hand_landmarks:
        for handLms in handResults.multi_hand_landmarks:
            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)

    frame_count += 1
    if frame_count % 2 == 0:
        faceResults = faceDetection.process(imgRGB)
        if faceResults.detections:
            detection = faceResults.detections[0]
            bboxC = detection.location_data.relative_bounding_box
            h, w, c = img.shape
            bbox = np.array([
                int(bboxC.xmin * w),
                int(bboxC.ymin * h),
                int(bboxC.width * w),
                int(bboxC.height * h)
            ])
            if bbox[2] * bbox[3] > 6000:
                if prev_bbox is None:
                    prev_bbox = bbox
                else:
                    prev_bbox = (alpha * bbox + (1 - alpha) * prev_bbox).astype(int)

    if prev_bbox is not None:
        x, y, w, h = prev_bbox
        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(img, "/root@arl", (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    cv2.imshow("WALA SI ARL TULOG! CHINAT GPT NYA LANG TO", img)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
